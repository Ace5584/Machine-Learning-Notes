{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cifar10.ipynb","provenance":[],"authorship_tag":"ABX9TyMKfR3LJfXSRTspr+8QIPzo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"YTyz3geQHRuS","executionInfo":{"status":"ok","timestamp":1603601917071,"user_tz":-660,"elapsed":2140,"user":{"displayName":"Alex Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxpvArds7xLNZB29BI3aCcSZkWbMPAZWZLOm3o=s64","userId":"03940255243131127536"}}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from functools import partial\n","import matplotlib.pyplot as plt\n","import os\n","import numpy as np\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ztq6BgmLHf4Q","executionInfo":{"status":"ok","timestamp":1603601918770,"user_tz":-660,"elapsed":2850,"user":{"displayName":"Alex Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxpvArds7xLNZB29BI3aCcSZkWbMPAZWZLOm3o=s64","userId":"03940255243131127536"}}},"source":["(train_data, train_label), (test_data, test_label) = keras.datasets.cifar10.load_data()\n","\n","model = keras.models.Sequential()\n","model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n","for _ in range(20):\n","    model.add(keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"))\n","model.add(keras.layers.Dense(10, activation=\"softmax\"))\n","\n","optimizer = keras.optimizers.Nadam(lr=5e-5)\n","model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n","\n","early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n","model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_model.h5\", save_best_only=True)\n","run_index = 1 # increment every time you train the model\n","run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_{:03d}\".format(run_index))\n","tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n","callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"0uxBOHl0K2A8","executionInfo":{"status":"ok","timestamp":1603594517756,"user_tz":-660,"elapsed":1040306,"user":{"displayName":"Alex Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxpvArds7xLNZB29BI3aCcSZkWbMPAZWZLOm3o=s64","userId":"03940255243131127536"}},"outputId":"121f1426-fbe6-4384-c98d-b66124304364","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.fit(train_data, train_label, epochs=100, validation_data=(test_data, test_label), callbacks=callbacks)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","\r   1/1563 [..............................] - ETA: 0s - loss: 3.8579 - accuracy: 0.1875WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n","Instructions for updating:\n","use `tf.profiler.experimental.stop` instead.\n","   2/1563 [..............................] - ETA: 1:43 - loss: 3.3483 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0185s vs `on_train_batch_end` time: 0.1144s). Check your callbacks.\n","1563/1563 [==============================] - 17s 11ms/step - loss: 2.3123 - accuracy: 0.1852 - val_loss: 2.1274 - val_accuracy: 0.2213\n","Epoch 2/100\n","1563/1563 [==============================] - 18s 11ms/step - loss: 2.0459 - accuracy: 0.2502 - val_loss: 2.0259 - val_accuracy: 0.2675\n","Epoch 3/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.9424 - accuracy: 0.2877 - val_loss: 1.8798 - val_accuracy: 0.3143\n","Epoch 4/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.8705 - accuracy: 0.3194 - val_loss: 1.8376 - val_accuracy: 0.3356\n","Epoch 5/100\n","1563/1563 [==============================] - 18s 12ms/step - loss: 1.8124 - accuracy: 0.3440 - val_loss: 1.7670 - val_accuracy: 0.3583\n","Epoch 6/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.7686 - accuracy: 0.3603 - val_loss: 1.7573 - val_accuracy: 0.3603\n","Epoch 7/100\n","1563/1563 [==============================] - 18s 11ms/step - loss: 1.7298 - accuracy: 0.3733 - val_loss: 1.7544 - val_accuracy: 0.3594\n","Epoch 8/100\n","1563/1563 [==============================] - 16s 11ms/step - loss: 1.7003 - accuracy: 0.3876 - val_loss: 1.6848 - val_accuracy: 0.3858\n","Epoch 9/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.6755 - accuracy: 0.3940 - val_loss: 1.6983 - val_accuracy: 0.3854\n","Epoch 10/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.6536 - accuracy: 0.4028 - val_loss: 1.6655 - val_accuracy: 0.3998\n","Epoch 11/100\n","1563/1563 [==============================] - 18s 11ms/step - loss: 1.6334 - accuracy: 0.4086 - val_loss: 1.6506 - val_accuracy: 0.4097\n","Epoch 12/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.6159 - accuracy: 0.4182 - val_loss: 1.6358 - val_accuracy: 0.4083\n","Epoch 13/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.5993 - accuracy: 0.4258 - val_loss: 1.6216 - val_accuracy: 0.4145\n","Epoch 14/100\n","1563/1563 [==============================] - 16s 10ms/step - loss: 1.5832 - accuracy: 0.4286 - val_loss: 1.6025 - val_accuracy: 0.4204\n","Epoch 15/100\n","1563/1563 [==============================] - 16s 11ms/step - loss: 1.5697 - accuracy: 0.4336 - val_loss: 1.6339 - val_accuracy: 0.4159\n","Epoch 16/100\n","1563/1563 [==============================] - 18s 11ms/step - loss: 1.5569 - accuracy: 0.4383 - val_loss: 1.6034 - val_accuracy: 0.4282\n","Epoch 17/100\n","1563/1563 [==============================] - 16s 11ms/step - loss: 1.5468 - accuracy: 0.4422 - val_loss: 1.6084 - val_accuracy: 0.4176\n","Epoch 18/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.5380 - accuracy: 0.4448 - val_loss: 1.5773 - val_accuracy: 0.4297\n","Epoch 19/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.5235 - accuracy: 0.4517 - val_loss: 1.5725 - val_accuracy: 0.4324\n","Epoch 20/100\n","1563/1563 [==============================] - 16s 10ms/step - loss: 1.5131 - accuracy: 0.4559 - val_loss: 1.5936 - val_accuracy: 0.4278\n","Epoch 21/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.5065 - accuracy: 0.4571 - val_loss: 1.5768 - val_accuracy: 0.4296\n","Epoch 22/100\n","1563/1563 [==============================] - 16s 11ms/step - loss: 1.4945 - accuracy: 0.4607 - val_loss: 1.5761 - val_accuracy: 0.4310\n","Epoch 23/100\n","1563/1563 [==============================] - 16s 10ms/step - loss: 1.4872 - accuracy: 0.4648 - val_loss: 1.5613 - val_accuracy: 0.4348\n","Epoch 24/100\n","1563/1563 [==============================] - 16s 10ms/step - loss: 1.4800 - accuracy: 0.4677 - val_loss: 1.5508 - val_accuracy: 0.4452\n","Epoch 25/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.4693 - accuracy: 0.4718 - val_loss: 1.5456 - val_accuracy: 0.4407\n","Epoch 26/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.4586 - accuracy: 0.4749 - val_loss: 1.6007 - val_accuracy: 0.4274\n","Epoch 27/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.4520 - accuracy: 0.4767 - val_loss: 1.5397 - val_accuracy: 0.4481\n","Epoch 28/100\n","1563/1563 [==============================] - 16s 11ms/step - loss: 1.4451 - accuracy: 0.4811 - val_loss: 1.5540 - val_accuracy: 0.4470\n","Epoch 29/100\n","1563/1563 [==============================] - 18s 11ms/step - loss: 1.4346 - accuracy: 0.4826 - val_loss: 1.5614 - val_accuracy: 0.4402\n","Epoch 30/100\n","1563/1563 [==============================] - 18s 11ms/step - loss: 1.4280 - accuracy: 0.4836 - val_loss: 1.5387 - val_accuracy: 0.4460\n","Epoch 31/100\n","1563/1563 [==============================] - 16s 10ms/step - loss: 1.4222 - accuracy: 0.4883 - val_loss: 1.5584 - val_accuracy: 0.4487\n","Epoch 32/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.4143 - accuracy: 0.4918 - val_loss: 1.5405 - val_accuracy: 0.4519\n","Epoch 33/100\n","1563/1563 [==============================] - 16s 10ms/step - loss: 1.4074 - accuracy: 0.4957 - val_loss: 1.5752 - val_accuracy: 0.4430\n","Epoch 34/100\n","1563/1563 [==============================] - 18s 12ms/step - loss: 1.4015 - accuracy: 0.4946 - val_loss: 1.5567 - val_accuracy: 0.4485\n","Epoch 35/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.3929 - accuracy: 0.4982 - val_loss: 1.5319 - val_accuracy: 0.4548\n","Epoch 36/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.3899 - accuracy: 0.5010 - val_loss: 1.5539 - val_accuracy: 0.4503\n","Epoch 37/100\n","1563/1563 [==============================] - 19s 12ms/step - loss: 1.3802 - accuracy: 0.5029 - val_loss: 1.5453 - val_accuracy: 0.4546\n","Epoch 38/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.3754 - accuracy: 0.5063 - val_loss: 1.5677 - val_accuracy: 0.4494\n","Epoch 39/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.3694 - accuracy: 0.5086 - val_loss: 1.5455 - val_accuracy: 0.4488\n","Epoch 40/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.3612 - accuracy: 0.5120 - val_loss: 1.5297 - val_accuracy: 0.4609\n","Epoch 41/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.3570 - accuracy: 0.5124 - val_loss: 1.5676 - val_accuracy: 0.4426\n","Epoch 42/100\n","1563/1563 [==============================] - 18s 11ms/step - loss: 1.3522 - accuracy: 0.5144 - val_loss: 1.5511 - val_accuracy: 0.4520\n","Epoch 43/100\n","1563/1563 [==============================] - 18s 12ms/step - loss: 1.3440 - accuracy: 0.5173 - val_loss: 1.5367 - val_accuracy: 0.4591\n","Epoch 44/100\n","1563/1563 [==============================] - 18s 11ms/step - loss: 1.3398 - accuracy: 0.5199 - val_loss: 1.5345 - val_accuracy: 0.4582\n","Epoch 45/100\n","1563/1563 [==============================] - 18s 12ms/step - loss: 1.3305 - accuracy: 0.5239 - val_loss: 1.5628 - val_accuracy: 0.4513\n","Epoch 46/100\n","1563/1563 [==============================] - 18s 11ms/step - loss: 1.3281 - accuracy: 0.5236 - val_loss: 1.5335 - val_accuracy: 0.4634\n","Epoch 47/100\n","1563/1563 [==============================] - 18s 11ms/step - loss: 1.3223 - accuracy: 0.5251 - val_loss: 1.5514 - val_accuracy: 0.4536\n","Epoch 48/100\n","1563/1563 [==============================] - 18s 12ms/step - loss: 1.3143 - accuracy: 0.5265 - val_loss: 1.5377 - val_accuracy: 0.4542\n","Epoch 49/100\n","1563/1563 [==============================] - 18s 11ms/step - loss: 1.3127 - accuracy: 0.5270 - val_loss: 1.5475 - val_accuracy: 0.4564\n","Epoch 50/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.3014 - accuracy: 0.5317 - val_loss: 1.5650 - val_accuracy: 0.4522\n","Epoch 51/100\n","1563/1563 [==============================] - 18s 12ms/step - loss: 1.3016 - accuracy: 0.5329 - val_loss: 1.5810 - val_accuracy: 0.4522\n","Epoch 52/100\n","1563/1563 [==============================] - 19s 12ms/step - loss: 1.2934 - accuracy: 0.5328 - val_loss: 1.5575 - val_accuracy: 0.4567\n","Epoch 53/100\n","1563/1563 [==============================] - 18s 12ms/step - loss: 1.2883 - accuracy: 0.5378 - val_loss: 1.5563 - val_accuracy: 0.4611\n","Epoch 54/100\n","1563/1563 [==============================] - 18s 11ms/step - loss: 1.2843 - accuracy: 0.5395 - val_loss: 1.5365 - val_accuracy: 0.4629\n","Epoch 55/100\n","1563/1563 [==============================] - 18s 12ms/step - loss: 1.2770 - accuracy: 0.5416 - val_loss: 1.5595 - val_accuracy: 0.4567\n","Epoch 56/100\n","1563/1563 [==============================] - 18s 12ms/step - loss: 1.2724 - accuracy: 0.5433 - val_loss: 1.5658 - val_accuracy: 0.4585\n","Epoch 57/100\n","1563/1563 [==============================] - 18s 12ms/step - loss: 1.2676 - accuracy: 0.5452 - val_loss: 1.5651 - val_accuracy: 0.4631\n","Epoch 58/100\n","1563/1563 [==============================] - 18s 11ms/step - loss: 1.2630 - accuracy: 0.5474 - val_loss: 1.5670 - val_accuracy: 0.4574\n","Epoch 59/100\n","1563/1563 [==============================] - 19s 12ms/step - loss: 1.2551 - accuracy: 0.5474 - val_loss: 1.5722 - val_accuracy: 0.4627\n","Epoch 60/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.2526 - accuracy: 0.5473 - val_loss: 1.5692 - val_accuracy: 0.4614\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f2545de1e10>"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"Jw_QSOdrnyRm","executionInfo":{"status":"ok","timestamp":1603606476675,"user_tz":-660,"elapsed":1421904,"user":{"displayName":"Alex Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxpvArds7xLNZB29BI3aCcSZkWbMPAZWZLOm3o=s64","userId":"03940255243131127536"}},"outputId":"e6837ac8-65e5-4421-825d-be8fff2c0a78","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model = keras.models.Sequential()\n","model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n","for _ in range(20):\n","    model.add(keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"))\n","    model.add(keras.layers.BatchNormalization())\n","model.add(keras.layers.Dense(10, activation=\"softmax\"))\n","\n","optimizer = keras.optimizers.Nadam(lr=5e-5)\n","model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n","\n","model.fit(train_data, train_label, epochs=30, validation_data=(test_data, test_label))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","1563/1563 [==============================] - 47s 30ms/step - loss: 2.2582 - accuracy: 0.2020 - val_loss: 2.0681 - val_accuracy: 0.2594\n","Epoch 2/30\n","1563/1563 [==============================] - 49s 32ms/step - loss: 1.9402 - accuracy: 0.2983 - val_loss: 1.8451 - val_accuracy: 0.3428\n","Epoch 3/30\n","1563/1563 [==============================] - 49s 31ms/step - loss: 1.8382 - accuracy: 0.3375 - val_loss: 1.7374 - val_accuracy: 0.3799\n","Epoch 4/30\n","1563/1563 [==============================] - 49s 32ms/step - loss: 1.7740 - accuracy: 0.3619 - val_loss: 1.7307 - val_accuracy: 0.3831\n","Epoch 5/30\n","1563/1563 [==============================] - 49s 31ms/step - loss: 1.7250 - accuracy: 0.3801 - val_loss: 1.6557 - val_accuracy: 0.4084\n","Epoch 6/30\n","1563/1563 [==============================] - 46s 29ms/step - loss: 1.6840 - accuracy: 0.3977 - val_loss: 1.6100 - val_accuracy: 0.4231\n","Epoch 7/30\n","1563/1563 [==============================] - 45s 28ms/step - loss: 1.6497 - accuracy: 0.4118 - val_loss: 1.5716 - val_accuracy: 0.4427\n","Epoch 8/30\n","1563/1563 [==============================] - 46s 29ms/step - loss: 1.6249 - accuracy: 0.4194 - val_loss: 1.5671 - val_accuracy: 0.4405\n","Epoch 9/30\n","1563/1563 [==============================] - 47s 30ms/step - loss: 1.6054 - accuracy: 0.4259 - val_loss: 1.5471 - val_accuracy: 0.4485\n","Epoch 10/30\n","1563/1563 [==============================] - 45s 29ms/step - loss: 1.5796 - accuracy: 0.4374 - val_loss: 1.5598 - val_accuracy: 0.4411\n","Epoch 11/30\n","1563/1563 [==============================] - 47s 30ms/step - loss: 1.5535 - accuracy: 0.4449 - val_loss: 1.6162 - val_accuracy: 0.4433\n","Epoch 12/30\n","1563/1563 [==============================] - 46s 30ms/step - loss: 1.5360 - accuracy: 0.4515 - val_loss: 1.5375 - val_accuracy: 0.4631\n","Epoch 13/30\n","1563/1563 [==============================] - 44s 28ms/step - loss: 1.5248 - accuracy: 0.4568 - val_loss: 1.4957 - val_accuracy: 0.4765\n","Epoch 14/30\n","1563/1563 [==============================] - 45s 29ms/step - loss: 1.5059 - accuracy: 0.4631 - val_loss: 1.5009 - val_accuracy: 0.4739\n","Epoch 15/30\n","1563/1563 [==============================] - 46s 29ms/step - loss: 1.4899 - accuracy: 0.4689 - val_loss: 1.5289 - val_accuracy: 0.4586\n","Epoch 16/30\n","1563/1563 [==============================] - 45s 29ms/step - loss: 1.4760 - accuracy: 0.4743 - val_loss: 1.5384 - val_accuracy: 0.4551\n","Epoch 17/30\n","1563/1563 [==============================] - 45s 29ms/step - loss: 1.4632 - accuracy: 0.4784 - val_loss: 1.4981 - val_accuracy: 0.4727\n","Epoch 18/30\n","1563/1563 [==============================] - 48s 30ms/step - loss: 1.4494 - accuracy: 0.4854 - val_loss: 1.5545 - val_accuracy: 0.4522\n","Epoch 19/30\n","1563/1563 [==============================] - 46s 29ms/step - loss: 1.4341 - accuracy: 0.4881 - val_loss: 1.5022 - val_accuracy: 0.4728\n","Epoch 20/30\n","1563/1563 [==============================] - 48s 30ms/step - loss: 1.4290 - accuracy: 0.4913 - val_loss: 1.4346 - val_accuracy: 0.4954\n","Epoch 21/30\n","1563/1563 [==============================] - 47s 30ms/step - loss: 1.4136 - accuracy: 0.4992 - val_loss: 1.4324 - val_accuracy: 0.4936\n","Epoch 22/30\n","1563/1563 [==============================] - 47s 30ms/step - loss: 1.4106 - accuracy: 0.4962 - val_loss: 1.4361 - val_accuracy: 0.4931\n","Epoch 23/30\n","1563/1563 [==============================] - 47s 30ms/step - loss: 1.3948 - accuracy: 0.5032 - val_loss: 1.6309 - val_accuracy: 0.4260\n","Epoch 24/30\n","1563/1563 [==============================] - 49s 32ms/step - loss: 1.3909 - accuracy: 0.5053 - val_loss: 1.4503 - val_accuracy: 0.4994\n","Epoch 25/30\n","1563/1563 [==============================] - 49s 31ms/step - loss: 1.3779 - accuracy: 0.5095 - val_loss: 1.4711 - val_accuracy: 0.4858\n","Epoch 26/30\n","1563/1563 [==============================] - 50s 32ms/step - loss: 1.3715 - accuracy: 0.5106 - val_loss: 1.4287 - val_accuracy: 0.4963\n","Epoch 27/30\n","1563/1563 [==============================] - 49s 31ms/step - loss: 1.3681 - accuracy: 0.5120 - val_loss: 1.4763 - val_accuracy: 0.4842\n","Epoch 28/30\n","1563/1563 [==============================] - 49s 31ms/step - loss: 1.3491 - accuracy: 0.5197 - val_loss: 1.4182 - val_accuracy: 0.5031\n","Epoch 29/30\n","1563/1563 [==============================] - 49s 31ms/step - loss: 1.3456 - accuracy: 0.5221 - val_loss: 1.4446 - val_accuracy: 0.4914\n","Epoch 30/30\n","1563/1563 [==============================] - 45s 29ms/step - loss: 1.3375 - accuracy: 0.5248 - val_loss: 1.4132 - val_accuracy: 0.5048\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fcccc74ccc0>"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"TFMPs62JTkNX","executionInfo":{"status":"ok","timestamp":1603607246045,"user_tz":-660,"elapsed":612153,"user":{"displayName":"Alex Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxpvArds7xLNZB29BI3aCcSZkWbMPAZWZLOm3o=s64","userId":"03940255243131127536"}},"outputId":"9dfce909-e0f8-4345-c83c-4a79353577b7","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model = keras.models.Sequential()\n","model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n","for _ in range(20):\n","    model.add(keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"))\n","model.add(keras.layers.AlphaDropout(rate=0.1))\n","model.add(keras.layers.Dense(10, activation=\"softmax\"))\n","\n","optimizer = keras.optimizers.Nadam(lr=5e-5)\n","model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n","\n","model.fit(train_data, train_label, epochs=100, validation_data=(test_data, test_label), callbacks=callbacks)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","   2/1563 [..............................] - ETA: 9:21 - loss: 3.3399 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0199s vs `on_train_batch_end` time: 0.6992s). Check your callbacks.\n","1563/1563 [==============================] - 18s 12ms/step - loss: 2.0594 - accuracy: 0.2575 - val_loss: 1.8314 - val_accuracy: 0.3397\n","Epoch 2/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.8066 - accuracy: 0.3439 - val_loss: 1.7168 - val_accuracy: 0.3832\n","Epoch 3/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.7208 - accuracy: 0.3783 - val_loss: 1.6508 - val_accuracy: 0.4088\n","Epoch 4/100\n","1563/1563 [==============================] - 18s 12ms/step - loss: 1.6536 - accuracy: 0.4026 - val_loss: 1.6193 - val_accuracy: 0.4293\n","Epoch 5/100\n","1563/1563 [==============================] - 18s 11ms/step - loss: 1.6041 - accuracy: 0.4217 - val_loss: 1.5869 - val_accuracy: 0.4365\n","Epoch 6/100\n","1563/1563 [==============================] - 18s 12ms/step - loss: 1.5653 - accuracy: 0.4387 - val_loss: 1.5823 - val_accuracy: 0.4424\n","Epoch 7/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.5361 - accuracy: 0.4520 - val_loss: 1.5729 - val_accuracy: 0.4475\n","Epoch 8/100\n","1563/1563 [==============================] - 18s 12ms/step - loss: 1.5094 - accuracy: 0.4594 - val_loss: 1.5973 - val_accuracy: 0.4497\n","Epoch 9/100\n","1563/1563 [==============================] - 19s 12ms/step - loss: 1.4864 - accuracy: 0.4686 - val_loss: 1.5328 - val_accuracy: 0.4570\n","Epoch 10/100\n","1563/1563 [==============================] - 18s 11ms/step - loss: 1.4652 - accuracy: 0.4742 - val_loss: 1.5060 - val_accuracy: 0.4745\n","Epoch 11/100\n","1563/1563 [==============================] - 18s 12ms/step - loss: 1.4486 - accuracy: 0.4818 - val_loss: 1.4819 - val_accuracy: 0.4777\n","Epoch 12/100\n","1563/1563 [==============================] - 18s 12ms/step - loss: 1.4292 - accuracy: 0.4881 - val_loss: 1.4919 - val_accuracy: 0.4751\n","Epoch 13/100\n","1563/1563 [==============================] - 18s 11ms/step - loss: 1.4080 - accuracy: 0.4965 - val_loss: 1.5681 - val_accuracy: 0.4685\n","Epoch 14/100\n","1563/1563 [==============================] - 18s 11ms/step - loss: 1.3981 - accuracy: 0.4985 - val_loss: 1.4762 - val_accuracy: 0.4825\n","Epoch 15/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.3811 - accuracy: 0.5042 - val_loss: 1.4869 - val_accuracy: 0.4802\n","Epoch 16/100\n","1563/1563 [==============================] - 18s 12ms/step - loss: 1.3657 - accuracy: 0.5122 - val_loss: 1.5339 - val_accuracy: 0.4736\n","Epoch 17/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.3508 - accuracy: 0.5158 - val_loss: 1.5116 - val_accuracy: 0.4826\n","Epoch 18/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.3381 - accuracy: 0.5218 - val_loss: 1.4925 - val_accuracy: 0.4854\n","Epoch 19/100\n","1563/1563 [==============================] - 18s 11ms/step - loss: 1.3244 - accuracy: 0.5251 - val_loss: 1.5430 - val_accuracy: 0.4739\n","Epoch 20/100\n","1563/1563 [==============================] - 18s 11ms/step - loss: 1.3088 - accuracy: 0.5325 - val_loss: 1.4857 - val_accuracy: 0.4886\n","Epoch 21/100\n","1563/1563 [==============================] - 19s 12ms/step - loss: 1.3011 - accuracy: 0.5333 - val_loss: 1.5093 - val_accuracy: 0.4898\n","Epoch 22/100\n","1563/1563 [==============================] - 18s 12ms/step - loss: 1.2863 - accuracy: 0.5391 - val_loss: 1.4859 - val_accuracy: 0.4968\n","Epoch 23/100\n","1563/1563 [==============================] - 18s 11ms/step - loss: 1.2711 - accuracy: 0.5453 - val_loss: 1.4907 - val_accuracy: 0.4931\n","Epoch 24/100\n","1563/1563 [==============================] - 18s 11ms/step - loss: 1.2631 - accuracy: 0.5466 - val_loss: 1.5026 - val_accuracy: 0.4955\n","Epoch 25/100\n","1563/1563 [==============================] - 18s 11ms/step - loss: 1.2468 - accuracy: 0.5533 - val_loss: 1.4993 - val_accuracy: 0.4981\n","Epoch 26/100\n","1563/1563 [==============================] - 18s 11ms/step - loss: 1.2414 - accuracy: 0.5538 - val_loss: 1.5311 - val_accuracy: 0.4831\n","Epoch 27/100\n","1563/1563 [==============================] - 19s 12ms/step - loss: 1.2302 - accuracy: 0.5577 - val_loss: 1.5012 - val_accuracy: 0.5005\n","Epoch 28/100\n","1563/1563 [==============================] - 18s 12ms/step - loss: 1.2209 - accuracy: 0.5625 - val_loss: 1.5216 - val_accuracy: 0.4849\n","Epoch 29/100\n","1563/1563 [==============================] - 18s 12ms/step - loss: 1.2093 - accuracy: 0.5648 - val_loss: 1.4886 - val_accuracy: 0.4962\n","Epoch 30/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.1957 - accuracy: 0.5692 - val_loss: 1.5625 - val_accuracy: 0.4948\n","Epoch 31/100\n","1563/1563 [==============================] - 18s 12ms/step - loss: 1.1804 - accuracy: 0.5747 - val_loss: 1.4970 - val_accuracy: 0.4957\n","Epoch 32/100\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.1747 - accuracy: 0.5770 - val_loss: 1.5527 - val_accuracy: 0.5004\n","Epoch 33/100\n","1563/1563 [==============================] - 19s 12ms/step - loss: 1.1687 - accuracy: 0.5803 - val_loss: 1.5215 - val_accuracy: 0.4998\n","Epoch 34/100\n","1563/1563 [==============================] - 19s 12ms/step - loss: 1.1526 - accuracy: 0.5873 - val_loss: 1.5098 - val_accuracy: 0.5070\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fccc9c587f0>"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"ImyuG9y3sxni","executionInfo":{"status":"ok","timestamp":1603611852970,"user_tz":-660,"elapsed":1931,"user":{"displayName":"Alex Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxpvArds7xLNZB29BI3aCcSZkWbMPAZWZLOm3o=s64","userId":"03940255243131127536"}},"outputId":"a9882920-1b38-4092-9e69-8cc49b333d88","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["model.evaluate(test_data, test_label)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["313/313 [==============================] - 1s 3ms/step - loss: 1.5098 - accuracy: 0.5070\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.509843111038208, 0.5070000290870667]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"I8DUaqgqtyk7","executionInfo":{"status":"ok","timestamp":1603612008168,"user_tz":-660,"elapsed":6353,"user":{"displayName":"Alex Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxpvArds7xLNZB29BI3aCcSZkWbMPAZWZLOm3o=s64","userId":"03940255243131127536"}},"outputId":"8a24c3dc-95d5-44aa-e23e-0919cbecd0f4","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["class MCAlphaDropout(keras.layers.AlphaDropout):\n","    def call(self, inputs):\n","        return super().call(inputs, training=True)\n","\n","mc_model = keras.models.Sequential([\n","    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n","    for layer in model.layers\n","])\n","\n","\n","def mc_dropout_predict_probas(mc_model, X, n_samples=10):\n","    Y_probas = [mc_model.predict(X) for sample in range(n_samples)]\n","    return np.mean(Y_probas, axis=0)\n","\n","def mc_dropout_predict_classes(mc_model, X, n_samples=10):\n","    Y_probas = mc_dropout_predict_probas(mc_model, X, n_samples)\n","    return np.argmax(Y_probas, axis=1)\n","\n","\n","keras.backend.clear_session()\n","tf.random.set_seed(42)\n","np.random.seed(42)\n","\n","y_pred = mc_dropout_predict_classes(mc_model, test_data)\n","accuracy = np.mean(y_pred == test_label[:, 0])\n","accuracy"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5069"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"R5bmuAcHu2YB","executionInfo":{"status":"ok","timestamp":1603612507020,"user_tz":-660,"elapsed":102548,"user":{"displayName":"Alex Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxpvArds7xLNZB29BI3aCcSZkWbMPAZWZLOm3o=s64","userId":"03940255243131127536"}},"outputId":"7f8d4f5b-5b56-4b30-f442-29e392f9d435","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["K = keras.backend\n","class OneCycleScheduler(keras.callbacks.Callback):\n","    def __init__(self, iterations, max_rate, start_rate=None,\n","                 last_iterations=None, last_rate=None):\n","        self.iterations = iterations\n","        self.max_rate = max_rate\n","        self.start_rate = start_rate or max_rate / 10\n","        self.last_iterations = last_iterations or iterations // 10 + 1\n","        self.half_iteration = (iterations - self.last_iterations) // 2\n","        self.last_rate = last_rate or self.start_rate / 1000\n","        self.iteration = 0\n","    def _interpolate(self, iter1, iter2, rate1, rate2):\n","        return ((rate2 - rate1) * (self.iteration - iter1)\n","                / (iter2 - iter1) + rate1)\n","    def on_batch_begin(self, batch, logs):\n","        if self.iteration < self.half_iteration:\n","            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n","        elif self.iteration < 2 * self.half_iteration:\n","            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n","                                     self.max_rate, self.start_rate)\n","        else:\n","            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n","                                     self.start_rate, self.last_rate)\n","            rate = max(rate, self.last_rate)\n","        self.iteration += 1\n","        K.set_value(self.model.optimizer.lr, rate)\n","\n","keras.backend.clear_session()\n","tf.random.set_seed(42)\n","np.random.seed(42)\n","\n","model = keras.models.Sequential()\n","model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n","for _ in range(20):\n","    model.add(keras.layers.Dense(100,\n","                                 kernel_initializer=\"lecun_normal\",\n","                                 activation=\"selu\"))\n","\n","model.add(keras.layers.AlphaDropout(rate=0.1))\n","model.add(keras.layers.Dense(10, activation=\"softmax\"))\n","\n","optimizer = keras.optimizers.SGD(lr=1e-2)\n","model.compile(loss=\"sparse_categorical_crossentropy\",\n","              optimizer=optimizer,\n","              metrics=[\"accuracy\"])\n","\n","n_epochs = 50\n","batch_size = 128\n","onecycle = OneCycleScheduler(len(train_data) // batch_size * n_epochs, max_rate=0.05)\n","history = model.fit(train_data, train_label, epochs=n_epochs, batch_size=batch_size,\n","                    validation_data=(test_data, test_label),\n","                    callbacks=[onecycle])"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","391/391 [==============================] - 2s 5ms/step - loss: 2.2456 - accuracy: 0.1908 - val_loss: 2.0530 - val_accuracy: 0.2623\n","Epoch 2/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.9945 - accuracy: 0.2739 - val_loss: 1.9440 - val_accuracy: 0.3026\n","Epoch 3/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.9097 - accuracy: 0.3081 - val_loss: 1.8380 - val_accuracy: 0.3401\n","Epoch 4/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.8550 - accuracy: 0.3278 - val_loss: 1.8782 - val_accuracy: 0.3182\n","Epoch 5/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.8242 - accuracy: 0.3437 - val_loss: 1.7168 - val_accuracy: 0.3839\n","Epoch 6/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.7975 - accuracy: 0.3507 - val_loss: 1.8008 - val_accuracy: 0.3648\n","Epoch 7/50\n","391/391 [==============================] - 2s 6ms/step - loss: 1.7696 - accuracy: 0.3599 - val_loss: 1.8196 - val_accuracy: 0.3628\n","Epoch 8/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.7587 - accuracy: 0.3710 - val_loss: 1.7303 - val_accuracy: 0.3789\n","Epoch 9/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.7363 - accuracy: 0.3787 - val_loss: 1.7383 - val_accuracy: 0.3835\n","Epoch 10/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.7166 - accuracy: 0.3860 - val_loss: 1.6823 - val_accuracy: 0.4110\n","Epoch 11/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.7048 - accuracy: 0.3921 - val_loss: 1.9321 - val_accuracy: 0.3181\n","Epoch 12/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.6872 - accuracy: 0.3984 - val_loss: 1.6662 - val_accuracy: 0.4026\n","Epoch 13/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.6738 - accuracy: 0.4042 - val_loss: 1.7175 - val_accuracy: 0.3978\n","Epoch 14/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.6590 - accuracy: 0.4093 - val_loss: 1.6403 - val_accuracy: 0.4206\n","Epoch 15/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.6467 - accuracy: 0.4157 - val_loss: 1.9141 - val_accuracy: 0.3221\n","Epoch 16/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.6479 - accuracy: 0.4138 - val_loss: 1.6243 - val_accuracy: 0.4281\n","Epoch 17/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.6256 - accuracy: 0.4235 - val_loss: 1.6196 - val_accuracy: 0.4225\n","Epoch 18/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.6156 - accuracy: 0.4250 - val_loss: 1.7874 - val_accuracy: 0.3592\n","Epoch 19/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.6052 - accuracy: 0.4282 - val_loss: 1.6915 - val_accuracy: 0.4068\n","Epoch 20/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.6056 - accuracy: 0.4332 - val_loss: 2.0573 - val_accuracy: 0.3349\n","Epoch 21/50\n","391/391 [==============================] - 2s 6ms/step - loss: 1.5887 - accuracy: 0.4367 - val_loss: 1.7072 - val_accuracy: 0.3967\n","Epoch 22/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.5726 - accuracy: 0.4393 - val_loss: 1.6485 - val_accuracy: 0.4263\n","Epoch 23/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.5711 - accuracy: 0.4446 - val_loss: 1.5963 - val_accuracy: 0.4398\n","Epoch 24/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.5389 - accuracy: 0.4526 - val_loss: 1.8217 - val_accuracy: 0.3718\n","Epoch 25/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.5149 - accuracy: 0.4601 - val_loss: 1.6293 - val_accuracy: 0.4426\n","Epoch 26/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.4896 - accuracy: 0.4687 - val_loss: 1.5489 - val_accuracy: 0.4613\n","Epoch 27/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.4641 - accuracy: 0.4752 - val_loss: 1.5716 - val_accuracy: 0.4557\n","Epoch 28/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.4428 - accuracy: 0.4845 - val_loss: 1.5883 - val_accuracy: 0.4479\n","Epoch 29/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.4247 - accuracy: 0.4909 - val_loss: 1.5894 - val_accuracy: 0.4585\n","Epoch 30/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.4047 - accuracy: 0.4985 - val_loss: 1.6292 - val_accuracy: 0.4364\n","Epoch 31/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.3848 - accuracy: 0.5076 - val_loss: 1.5421 - val_accuracy: 0.4713\n","Epoch 32/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.3637 - accuracy: 0.5140 - val_loss: 1.4932 - val_accuracy: 0.4818\n","Epoch 33/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.3491 - accuracy: 0.5204 - val_loss: 1.5492 - val_accuracy: 0.4673\n","Epoch 34/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.3287 - accuracy: 0.5249 - val_loss: 1.5003 - val_accuracy: 0.4799\n","Epoch 35/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.3063 - accuracy: 0.5316 - val_loss: 1.5547 - val_accuracy: 0.4772\n","Epoch 36/50\n","391/391 [==============================] - 2s 6ms/step - loss: 1.2882 - accuracy: 0.5394 - val_loss: 1.5508 - val_accuracy: 0.4735\n","Epoch 37/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.2703 - accuracy: 0.5444 - val_loss: 1.4962 - val_accuracy: 0.4923\n","Epoch 38/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.2463 - accuracy: 0.5526 - val_loss: 1.5503 - val_accuracy: 0.4849\n","Epoch 39/50\n","391/391 [==============================] - 2s 6ms/step - loss: 1.2280 - accuracy: 0.5588 - val_loss: 1.5419 - val_accuracy: 0.4852\n","Epoch 40/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.2079 - accuracy: 0.5656 - val_loss: 1.5874 - val_accuracy: 0.4846\n","Epoch 41/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.1873 - accuracy: 0.5731 - val_loss: 1.5135 - val_accuracy: 0.4943\n","Epoch 42/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.1663 - accuracy: 0.5776 - val_loss: 1.5876 - val_accuracy: 0.4903\n","Epoch 43/50\n","391/391 [==============================] - 2s 6ms/step - loss: 1.1440 - accuracy: 0.5872 - val_loss: 1.5311 - val_accuracy: 0.4912\n","Epoch 44/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.1190 - accuracy: 0.5949 - val_loss: 1.5387 - val_accuracy: 0.4974\n","Epoch 45/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.0988 - accuracy: 0.6006 - val_loss: 1.5585 - val_accuracy: 0.4997\n","Epoch 46/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.0762 - accuracy: 0.6093 - val_loss: 1.5680 - val_accuracy: 0.5000\n","Epoch 47/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.0636 - accuracy: 0.6137 - val_loss: 1.5749 - val_accuracy: 0.5004\n","Epoch 48/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.0497 - accuracy: 0.6172 - val_loss: 1.5904 - val_accuracy: 0.5009\n","Epoch 49/50\n","391/391 [==============================] - 2s 5ms/step - loss: 1.0368 - accuracy: 0.6233 - val_loss: 1.6008 - val_accuracy: 0.5006\n","Epoch 50/50\n","391/391 [==============================] - 2s 6ms/step - loss: 1.0262 - accuracy: 0.6257 - val_loss: 1.6024 - val_accuracy: 0.4989\n"],"name":"stdout"}]}]}